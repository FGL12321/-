[TOC]



# 电商客服案例笔记

# 1.0业务流程

![1660893847839](https://pic-1313413291.cos.ap-nanjing.myqcloud.com/1660893847839.png)

## 1.1 模块①—数据的生产-采集-消费（P1-P13）

![1660893874562](https://pic-1313413291.cos.ap-nanjing.myqcloud.com/1660893874562.png)

### 1.1.1创建生产者

#### P6尚硅谷_数据生产 - 创建生产者对象04:25

```
public class Bootstrap {
    public static void main(String[] args) throws IOException {


        if(args.length<2){
            System.out.println("系统参数不正确，请按照指定格式传递");
            System.exit(1);
        }

        //构建生产者对象
        Producer producer=new LocalFileProducer();


//        producer.setIn(new LocalFileDataIn("D:\\大数据学习资料\\尚硅谷大数据技术之电信客服综合案例\\2.资料\\辅助文档\\contact.log"));
//        producer.setOut(new LocalFileDataOut("D:\\大数据学习资料\\尚硅谷大数据技术之电信客服综合案例\\2.资料\\辅助文档\\call.log"));


        producer.setIn(new LocalFileDataIn(args[0]));
        producer.setOut(new LocalFileDataOut(args[1]));

        //生产数据
        producer.producer();

        //关闭生产者对象
        producer.close();
    }
}
```

#### P7尚硅谷_数据生产 - 获取通讯录数据33:32

==创建输入流，将数据保存到集合中==

```
public class LocalFileDataIn implements DataIn {

    private BufferedReader reader = null;

    /**
     * 构造方法
     * @param path
     */
    public LocalFileDataIn(String path) {
        setPath(path);
    }

    /**
     * 设置路径
     * 创建输入流
     * @param path
     */
    public void setPath(String path) {
        try {
            reader = new BufferedReader(new InputStreamReader(new FileInputStream(path), "UTF-8"));
        } catch (UnsupportedEncodingException e) {
            e.printStackTrace();
        } catch (FileNotFoundException e) {
            e.printStackTrace();
        }
    }

    public Object read() throws IOException {
        return null;
    }

    /**
     * 读取数据，将数据返回到集合中
     *
     * @param <T>
     * @param clazz
     * @throws IOException
     * @return
     */
    public <T extends Data> List<T> read(Class<T> clazz) throws IOException {

        List<T> ts = new ArrayList<T>();

        try {
            //从数据文件中读取所有的数据
            String line = null;
            while ((line = reader.readLine()) != null) {
                //将数据转换为指定类型的对象，封装为集合返回
                T t = (T) clazz.newInstance();
                t.setValue(line);
                ts.add(t);
            }
        } catch (Exception e) {
            e.printStackTrace();
        }
        return ts;
    }

    /**
     * 关闭资源
     * @throws IOException
     */
    public void close() throws IOException {
      if (reader!=null){
          reader.close();
      }
    }
}
```

#### P8尚硅谷_数据生产 - 随机生成主被叫电话号码12:59

==从集合中获取两条数据构成主叫和被叫，并随机生成通话 日期和时间==

```
/**
 * 本地数据文件的生产者
 */
public class LocalFileProducer implements Producer {

    /**
     * 数据来源
     * @param in
     */
    private DataIn in;
    private DataOut out;
    private volatile boolean flg=true; //增强内存可见性

    public void setIn(DataIn in) {
          this.in=in;
    }

    /**
     * 数据输出
     * @param out
     */
    public void setOut(DataOut out) {
          this.out=out;
    }

    /**
     * 数据生产
     */
    public void producer() {

        /**
         * 数据返回类型为一个对象
         */
        try {

            List<Contact> contacts=in.read(Contact.class);

            //读取通讯录的数据
            while ( flg ){

                int call1Index=new Random().nextInt(contacts.size());
                int call2Index;
                while (true){
                    call2Index=new Random().nextInt(contacts.size());
                    if (call1Index!=call2Index){
                       break;
                    }
                }

                Contact call1=contacts.get(call1Index);
                Contact call2=contacts.get(call2Index);

                //生成随机的通话时间
                String startDate="20180101000000";  //开始时间
                String endDate="20190101000000";    //结束时间

                long startTime= DataUtil.parse(startDate,"yyyyMMddHHmmss").getTime();
                //通话时间
                long endtime=DataUtil.parse(endDate,"yyyyMMddHHmmss").getTime();

                //通话时间字符串
                long  calltime=startTime+(long)((endtime-startTime)* Math.random());
                //通话时间字符串
                String callTimeString=DataUtil.format(new Date(calltime),"yyyyMMddHHmmss");

                //生成随机的通话时长
                 String duration= NumberUtil.format(new Random().nextInt(3000),4);

                //生成通话记录
                Callog log=new Callog(call1.getTel(),call2.getTel(),callTimeString,duration);
                System.out.println(log);
                //将通话记录写入到数据文件中
                out.write(log);
                Thread.sleep(500);
            }
        }catch (Exception e){
            e.printStackTrace();
        }
    }

    /**
     * 关闭生产者
     * @throws IOException
     */
    public void close() throws IOException {

        if (in!=null){

            in.close();
        }
        if (out!=null){
            out.close();
        }

    }
}

```

#### P9尚硅谷_数据生产 - 构建通话记录25:40

==将数据封装为对象输出到通话日志中==

```
/**
 * 本地文件数据输出
 */
public class LocalFileDataOut implements DataOut {

    private PrintWriter writer=null;

    public LocalFileDataOut(String path){
        setPath(path);
    }
    /**
     * 设置路径
     * @param path
     */
    public void setPath(String path) {
        try {
            writer=new PrintWriter(new OutputStreamWriter(new FileOutputStream(path),"UTF-8"));
        } catch (UnsupportedEncodingException e) {
            e.printStackTrace();
        } catch (FileNotFoundException e) {
            e.printStackTrace();
        }

    }

    public void write(Object data) throws Exception {
         write(data.toString());
    }

    /**
     * 将数据字符串生成到文件中
     * @param data
     * @throws Exception
     */
    public void write(String data) throws Exception {
         writer.println(data);
         writer.flush();
    }

    /**
     * 释放资源
     * @throws IOException
     */
    public void close() throws IOException {

        if(writer!=null){
            writer.close();
        }
    }
}

```

```
public class Callog {
    private String call1;
    private String call2;
    private String calltime;
    private String duration;

    public Callog(String call1, String call2, String calltime, String duration) {
        this.call1 = call1;
        this.call2 = call2;
        this.calltime = calltime;
        this.duration = duration;
    }

    @Override
    public String toString() {
        return call1+"\t"+call2+"\t"+calltime+"\t"+duration;

    }

    public String getCall1() {
        return call1;
    }

    public void setCall1(String call1) {
        this.call1 = call1;
    }

    public String getCall2() {
        return call2;
    }

    public void setCall2(String call2) {
        this.call2 = call2;
    }

    public String getCalltime() {
        return calltime;
    }

    public void setCalltime(String calltime) {
        this.calltime = calltime;
    }

    public String getDuration() {
        return duration;
    }

    public void setDuration(String duration) {
        this.duration = duration;
    }
}
```

### 1.1.3数据采集和消费

==配置Flume的配置文件监听日志信息和Kafka输出存储区==

==在kafka创建一个ct的数据存储区开启kafka获取到数据==



**到指定目录下配置flume**

```
[fang@hadoop102 kafka]$ cd /opt/module/data/
[fang@hadoop102 data]$ vim flume-2-kafka.conf
```

```
# define
a1.sources = r1
a1.sinks = k1
a1.channels = c1

# source
a1.sources.r1.type = exec
a1.sources.r1.command = tail -F -c +0 /opt/module/data/call.log
a1.sources.r1.shell = /bin/bash -c

# sink
a1.sinks.k1.type = org.apache.flume.sink.kafka.KafkaSink
a1.sinks.k1.kafka.bootstrap.servers = hadoop102:9092,hadoop103:9092,hadoop104:9092
a1.sinks.k1.kafka.topic = ct
a1.sinks.k1.kafka.flumeBatchSize = 20
a1.sinks.k1.kafka.producer.acks = 1
a1.sinks.k1.kafka.producer.linger.ms = 1

# channel
a1.channels.c1.type = memory
a1.channels.c1.capacity = 1000
a1.channels.c1.transactionCapacity = 100

# bind
a1.sources.r1.channels = c1
a1.sinks.k1.channel = c1
```

**启动jar包：**

```
[fang@hadoop102 data]$ java -jar ct_producer.jar contact.log call.log 
```

**在kafka目录下创建topic：**

```
bin/kafka-topics.sh --bootstrap-server hadoop102:9092 --create --topic ct --partitions 3 --replication-factor 2
```

**kafka开始消费**

```
bin/kafka-console-consumer.sh --bootstrap-server hadoop102:9092 -topic ct
```

**启动flume对数据进行采集：**

```
bin/flume-ng agent -c conf/ -n a1 -f /opt/module/data/flume-2-kafka.conf 
```



==使用Kafka消费者API获取数据，并将数据发送到Hbase中==

```
/**
 * 启动Kafka消费者
 *
 */
//使用kafka消费者获取Flume采集数据

//将数据存储到HBase中
public class Bootstrap {
    public static void main(String[] args) throws IOException {

        //创建消费者
        Consumer consumer=new CallogConsumer();

        //消费数据
        consumer.consume();

        //关闭资源
        consumer.close();

    }
}
```

```
/**
 * 通话日志消费者
 */
public class CallogConsumer implements Consumer {

    /**
     * 消费数据
     */
    public void consume() {

        try {
            //创建配置对象
            Properties prop =new Properties();
            prop.load(Thread.currentThread().getContextClassLoader().getResourceAsStream("consumer.properties"));

            //获取flume采集的数据
            KafkaConsumer<String,String> consumer=new KafkaConsumer<String, String>(prop);

            //关注主题
            consumer.subscribe(Arrays.asList(Names.TOPIC.getValue()));

            //HBase数据访问对象
            HBaseDao dao=new HBaseDao();

            dao.init();//初始化HBase

            //消费数据
            while (true){
                ConsumerRecords<String, String> consumerRecords = consumer.poll(100);
                for (ConsumerRecord<String, String> consumerRecord : consumerRecords) {
                    System.out.println(consumerRecord.value());
                    dao.insertData(consumerRecord.value());//将数据插入HBase中
                    //Callog log=new Callog(consumerRecord.value());

                    //dao.insertData(log);
                }
            }
        } catch (IOException e) {
            e.printStackTrace();
        } catch (Exception e) {
            e.printStackTrace();
        }
    }

    /**
     * 关闭资源
     * @throws IOException
     */
    public void close() throws IOException {

    }
}
```

## 1.2 模块②—HBase数据消费（P14-P22）

![1660893904098](https://pic-1313413291.cos.ap-nanjing.myqcloud.com/1660893904098.png)

### 1.2.1建表

#### P14尚硅谷__数据消费 - Hbase数据访问封装32:21

==在Hbase中创建对应的表格，设置两个列族和rowkey==

```
/**
 * HBase的数据访问对象
 */
public class HBaseDao extends BaseDao {
    /**
     * 初始化
     */
    public void init() throws Exception {
        start();

        //创建命名空间ct
        createNamespaseNX(Names.NAMESPACE.getValue());

        //创建表名ct:calllog 分区数为6
        createTableXX(Names.TABLE.getValue(),"com.fang.ct.consumer.coprocessor.InsertCalleeCoprocessor", 6,Names.CF_CALLER.getValue(),Names.CF_CALLEE.getValue());

        end();
    }

    /**
     * 插入对象
     * @param log
     * @throws Exception
     */
    public void insertData(Callog log) throws Exception{
        log.setRowkey(genRegionNum(log.getCall1(),log.getCalltime())+"_"+log.getCall1()+"_"+log.getCalltime()+"_"+log.getCall2()+"_"+log.getDuration());

        putData(log);

    }


    /**
     * 插入数据
     */
    public void insertData(String value) throws Exception{

        //将通话日志保存到Hbase的表中

        //1.获取通话日志数据
        String[] values= value.split("\t");
        String call1=values[0];
        String call2=values[1];
        String calltime=values[2];
        String duration=values[3];

        //2.创建数据对象
        //rowkey设计

        //主叫用户
        String rowkey=genRegionNum(call1,calltime)+"_"+call1+"_"+calltime+"_"+call2+"_"+duration+ "_1";
        Put put =new Put(Bytes.toBytes(rowkey));
        byte[] family=Bytes.toBytes(Names.CF_CALLER.getValue());
        put.addColumn(family,Bytes.toBytes("call1"),Bytes.toBytes(call1));
        put.addColumn(family,Bytes.toBytes("call2"),Bytes.toBytes(call2));
        put.addColumn(family,Bytes.toBytes("calltime"),Bytes.toBytes(calltime));
        put.addColumn(family,Bytes.toBytes("duration"),Bytes.toBytes(duration));
        put.addColumn(family, Bytes.toBytes("flg"), Bytes.toBytes("1"));


       String calleeRowkey = genRegionNum(call2, calltime) + "_" + call2 + "_" + calltime + "_" + call1 + "_" + duration + "_0";

//        // 被叫用户
//        Put calleePut = new Put(Bytes.toBytes(calleeRowkey));
//        byte[] calleeFamily = Bytes.toBytes(Names.CF_CALLEE.getValue());
//        calleePut.addColumn(calleeFamily, Bytes.toBytes("call1"), Bytes.toBytes(call2));
//        calleePut.addColumn(calleeFamily, Bytes.toBytes("call2"), Bytes.toBytes(call1));
//        calleePut.addColumn(calleeFamily, Bytes.toBytes("calltime"), Bytes.toBytes(calltime));
//        calleePut.addColumn(calleeFamily, Bytes.toBytes("duration"), Bytes.toBytes(duration));
//        calleePut.addColumn(calleeFamily, Bytes.toBytes("flg"), Bytes.toBytes("0"));



        // 3. 保存数据
        List<Put> puts = new ArrayList<Put>();
        puts.add(put);
       // puts.add(calleePut);

        putData(Names.TABLE.getValue(), puts);
    }
}
```

==获取连接对象，设置表的相关方法，生成分区键，分区号，数据的插入，删除等==

```
/**
 * 基础的数据访问对象
 */
public abstract class BaseDao {


    /**
     *
     */
    private ThreadLocal<Connection> connHolder=new ThreadLocal<Connection>();
    private ThreadLocal<Admin> adminHolder=new ThreadLocal<Admin>();

    protected void start() throws Exception{
        getConnection();
        getAdmin();
    }

    protected void end() throws Exception{
        Admin admin=getAdmin();
        if (admin!=null){
            admin.close();
            adminHolder.remove();
        }
        Connection conn=getConnection();
        if (conn!=null){
            conn.close();;
            connHolder.remove();
        }

    }

    /**
     * 创建表，如果表已经存在，name删除后创建新的
     * @param name
     * @param family
     * @throws IOException
     */
    protected void createTableXX(String name,String... family) throws Exception {
        createTableXX(name,null,null,family);
    }

    protected void createTableXX(String name,String coprocessorClass,Integer regionCount,String... family) throws Exception {
        Admin admin=getAdmin();
        TableName tableName= TableName.valueOf(name);

        if (admin.tableExists(tableName)){
            //表存在，删除表
            deleteTable(name);
        }

        //创建表
        createTable(name,coprocessorClass,regionCount,family);
    }


    private void createTable(String name,String coprocessorClass,Integer regionCount,String... family) throws Exception{
        Admin admin=getAdmin();
        TableName tablename=TableName.valueOf(name);

        HTableDescriptor tableDescriptor=new HTableDescriptor(tablename);
        
        if (family==null||family.length==0){
            family=new String[1];
            family[0]= Names.CF_INFO.getValue();

        }
        for (String families : family) {
            HColumnDescriptor columnDescriptor=
                    new HColumnDescriptor(families);
            tableDescriptor.addFamily(columnDescriptor);
        }

        if(coprocessorClass!=null&& !"".equals(coprocessorClass)){
            tableDescriptor.addCoprocessor(coprocessorClass);
        }


        //增加预分区
        if(regionCount==null||regionCount<=0){
            admin.createTable(tableDescriptor);
        }else {
            //分区键
            byte[][] splitKeys=genSpliKeys(regionCount);
            admin.createTable(tableDescriptor,splitKeys);
        }
    }

    /**
     * 获取查询时startrow，stoprom集合
     * @return
     */
    protected  List<String[]> getStartStorRowkeys(String tel,String start,String end){
        List<String[]> rowkeyss=new ArrayList<String[]>();

        String startTime = start.substring(0, 6);
        String endTime = end.substring(0, 6);

        Calendar startCal = Calendar.getInstance();
        startCal.setTime(DataUtil.parse(startTime, "yyyyMM"));

        Calendar endCal = Calendar.getInstance();
        endCal.setTime(DataUtil.parse(endTime, "yyyyMM"));

        while (startCal.getTimeInMillis() <= endCal.getTimeInMillis()) {

            // 当前时间
            String nowTime = DataUtil.format(startCal.getTime(), "yyyyMM");

            int regionNum = genRegionNum(tel, nowTime);

            String startRow = regionNum + "_" + tel + "_" + nowTime;
            String stopRow = startRow + "|";

            String[] rowkeys = {startRow, stopRow};
            rowkeyss.add(rowkeys);

            // 月份+1
            startCal.add(Calendar.MONTH, 1);
        }
        return  rowkeyss;

    }
    /**
     * 计算分区号
     * @param tel
     * @param date
     * @return
     */
    protected  int genRegionNum(String tel,String date){
        String usercode=tel.substring(tel.length()-4);
        String yearMonth=date.substring(0,6);
        int userCodehash=usercode.hashCode();
        int yearMonthHash=yearMonth.hashCode();

        //crc校验采用异或算法
        int crc=Math.abs(userCodehash ^ yearMonthHash);
        //取模
        int regionNum=crc% ValueConstant.REGION_COUNT;
        return regionNum;
    }

    /**
     * 生成分区键
     * @return
     */
    private  byte[][] genSpliKeys(int regionCount){

        int splitkeyCount=regionCount-1;
        byte[][] bs=new byte[splitkeyCount][];
        //0,1,2,3,4
        List<byte[]> bsList=new ArrayList<byte[]>();
        for (int i = 0; i < splitkeyCount; i++) {
            String splitkey=i+"|";
            bsList.add(Bytes.toBytes(splitkey));
        }

        //Collections.sort(bsList,new Bytes.ByteArrayComparator());

        bsList.toArray(bs);
        return bs;
    }




    /**
     * 增加对象：自动封装数据，将对象数据直接保存到Hbase中
     * @param obj
     * @throws Exception
     */
    protected void putData(Object obj) throws Exception{
        // 反射
        Class clazz = obj.getClass();
        TableRef tableRef = (TableRef)clazz.getAnnotation(TableRef.class);
        String tableName = tableRef.value();

        Field[] fs = clazz.getDeclaredFields();
        String stringRowkey = "";
        for (Field f : fs) {
            Rowkey rowkey = f.getAnnotation(Rowkey.class);
            if ( rowkey != null ) {
                f.setAccessible(true);
                stringRowkey = (String)f.get(obj);
                break;
            }
        }

        //获取表对象
        Connection connection=getConnection();
        Table table = connection.getTable(TableName.valueOf(tableName));
        Put put=new Put(Bytes.toBytes(stringRowkey));
        for (Field f : fs) {
            Column column = f.getAnnotation(Column.class);
            if (column != null) {
                String family = column.family();
                String colName = column.column();
                if (colName == null || "".equals(colName)) {
                    colName = f.getName();
                }
                f.setAccessible(true);
                String value = (String) f.get(obj);

                put.addColumn(Bytes.toBytes(family), Bytes.toBytes(colName), Bytes.toBytes(value));

            }
        }
        //增加数据
        table.put(put);
        //关闭表
        table.close();

    }


    /**
     * 增加多条数据
     * @param name
     * @param puts
     * @throws IOException
     */
    protected void putData( String name, List<Put> puts ) throws Exception {

        // 获取表对象
        Connection conn = getConnection();
        Table table = conn.getTable(TableName.valueOf(name));

        // 增加数据
        table.put(puts);

        // 关闭表
        table.close();
    }

    /**
     * 增加数据
     * @param name
     * @param put
     */

    protected  void putData(String name, Put put) throws IOException {
        //获取表对象
        Connection connection=getConnection();
        Table table = connection.getTable(TableName.valueOf(name));
        //增加数据
        table.put(put);
        //关闭表
        table.close();
    }

    /**
     * 删除表格
     * @param name
     * @throws Exception
     */
    protected  void deleteTable(String name) throws Exception{
        TableName tableName=TableName.valueOf(name);
        Admin admin=getAdmin();
        admin.disableTable(tableName);
        admin.deleteTable(tableName);
    }

    /**
     * 创建命名空间，如果命名空间已经存在，不需要创建，否则创建新的
     * @param namespace
     */
    protected void createNamespaseNX(String namespace) throws IOException {

        Admin admin =getAdmin();

        try{
            admin.getNamespaceDescriptor(namespace);
        }catch (NamespaceNotFoundException e){

           admin.createNamespace(NamespaceDescriptor.create(namespace).build());
        }
    }

    /**
     * 获取管理对象
     */
    protected synchronized Admin getAdmin() throws IOException {
        Admin admin = adminHolder.get();
        if(admin==null){
            admin=getConnection().getAdmin();
            adminHolder.set(admin);
        }
        return admin;
    }

    /**
     * 获取连接对象
     * @return
     */
    protected synchronized Connection getConnection() throws IOException {
        Connection conn=connHolder.get();
        if(conn==null){
            Configuration conf= HBaseConfiguration.create();
            conn= ConnectionFactory.createConnection(conf);
            connHolder.set(conn);
        }

        return conn;
    }

}

```

### 1.2.4配置协处理器

==用于区分主叫和被叫，减少数据的插入量==

```
/**
 *
 * 使用协处理器保存被叫用户的数据
 *
 * 协处理器的使用
 * 1. 创建类
 * 2. 让表找到协处理类（和表有关联）
 * 3. 将项目打成jar包发布到hbase中（关联的jar包也需要发布），并且需要分发
 */
public class InsertCalleeCoprocessor extends BaseRegionObserver {

    // 方法的命名规则
    // login
    // logout
    // prePut
    // doPut ：模板方法设计模式
    //    存在父子类：
    //    父类搭建算法的骨架
    //    1. tel取用户代码，2时间取年月，3，异或运算，4 hash散列
    //    子类重写算法的细节
    //    do1. tel取后4位，do2，201810， do3 ^, 4, % &
    // postPut

    /**
     * 保存主叫用户数据之后，由Hbase自动保存被叫用户数据
     * @param e
     * @param put
     * @param edit
     * @param durability
     * @throws IOException
     */
    @Override
    public void postPut(ObserverContext<RegionCoprocessorEnvironment> e, Put put, WALEdit edit, Durability durability) throws IOException {

        // 获取表
        Table table = e.getEnvironment().getTable(TableName.valueOf(Names.TABLE.getValue()));

        // 主叫用户的rowkey
        String rowkey = Bytes.toString(put.getRow());
        // 1_133_2019_144_1010_1
        String[] values = rowkey.split("_");

        CoprocessorDao dao = new CoprocessorDao();
        String call1 = values[1];
        String call2 = values[3];
        String calltime = values[2];
        String duration = values[4];
        String flg = values[5];

        if ( "1".equals(flg) ) {
            // 只有主叫用户保存后才需要触发被叫用户的保存
            String calleeRowkey = dao.getRegionNum(call2, calltime) + "_" + call2 + "_" + calltime + "_" + call1 + "_" + duration + "_0";

            // 保存数据
            Put calleePut = new Put(Bytes.toBytes(calleeRowkey));
            byte[] calleeFamily = Bytes.toBytes(Names.CF_CALLEE.getValue());
            calleePut.addColumn(calleeFamily, Bytes.toBytes("call1"), Bytes.toBytes(call2));
            calleePut.addColumn(calleeFamily, Bytes.toBytes("call2"), Bytes.toBytes(call1));
            calleePut.addColumn(calleeFamily, Bytes.toBytes("calltime"), Bytes.toBytes(calltime));
            calleePut.addColumn(calleeFamily, Bytes.toBytes("duration"), Bytes.toBytes(duration));
            calleePut.addColumn(calleeFamily, Bytes.toBytes("flg"), Bytes.toBytes("0"));
            table.put( calleePut );


        }
        // 关闭表
        table.close();

    }

    private class CoprocessorDao extends BaseDao {

        public int getRegionNum(String tel, String time) {
            return genRegionNum(tel, time);
        }
    }
}
```

## 1.3 模块③—导出数据及运算（P23-P29）

![1660893925799](https://pic-1313413291.cos.ap-nanjing.myqcloud.com/1660893925799.png)

### 1.3.1数据库表设计

![1660887584035](https://pic-1313413291.cos.ap-nanjing.myqcloud.com/1660887584035.png)



![1660887605668](https://pic-1313413291.cos.ap-nanjing.myqcloud.com/1660887605668.png)

![1660887560833](https://pic-1313413291.cos.ap-nanjing.myqcloud.com/1660887560833.png)

### 1.3.2数据计算

==用于map和reduce，通过对应的方法获取Hbase的数据==

```
/**
 * 分析数据工具类
 */
public class AnalysisTextTool implements Tool {

    public int run(String[] args) throws Exception {

        Job job = Job.getInstance();
        job.setJarByClass(AnalysisTextTool.class);


        //从Hbase中读去数据
        Scan scan = new Scan();
        scan.addFamily(Bytes.toBytes(Names.CF_CALLER.getValue()));

        // mapper
        TableMapReduceUtil.initTableMapperJob(
                Names.TABLE.getValue(),
                scan,
                AnalysisTextMapper.class,
                Text.class,
                Text.class,
                job
        );

        // reducer
        job.setReducerClass(AnalysisTextReducer.class);
        job.setOutputKeyClass(Text.class);
        job.setOutputValueClass(Text.class);


        job.setOutputFormatClass(MySQLRedisTextOutputFormat.class);

        boolean flg = job.waitForCompletion(true);
        if ( flg ) {
            return JobStatus.State.SUCCEEDED.getValue();
        } else {
            return JobStatus.State.FAILED.getValue();
        }
    }

    public void setConf(Configuration configuration) {

    }

    public Configuration getConf() {
        return null;
    }
}

```

==将从Hbase中获取到的数据进行拆封，封装为集合==

```
/**
 * maper
 */
public class AnalysisTextMapper extends TableMapper<Text, Text> {
    @Override
    protected void map(ImmutableBytesWritable key, Result value, Context context) throws IOException, InterruptedException {

        String rowkey = Bytes.toString(key.get());

        String[] values = rowkey.split("_");

        String call1 = values[1];
        String call2 = values[3];
        String calltime = values[2];
        String duration = values[4];

        String year = calltime.substring(0, 4);
        String month = calltime.substring(0, 6);
        String date= calltime.substring(0, 8);

        // 主叫用户 - 年
        context.write(new Text(call1+"_"+year), new Text(duration));
        // 主叫用户 - 月
        context.write(new Text(call1+"_"+month), new Text(duration));
        // 主叫用户 - 日
        context.write(new Text(call1+"_"+date), new Text(duration));

        // 被叫用户 - 年
        context.write(new Text(call2+"_"+year), new Text(duration));
        // 被叫用户 - 月
        context.write(new Text(call2+"_"+month), new Text(duration));
        // 被叫用户 - 日
        context.write(new Text(call2+"_"+date), new Text(duration));
    }
}

```

==获取到Mapper的数据对数据进行对应的运算==

```
/**
 * 分析数据的Reducer
 */
public class AnalysisTextReducer extends Reducer<Text,Text,Text,Text>{

    @Override
    protected void reduce(Text key, Iterable<Text> values, Context context) throws IOException, InterruptedException {

        int sumCall = 0;
        int sumDuration = 0;

        for (Text value : values) {
            int duration = Integer.parseInt(value.toString());
            sumDuration = sumDuration + duration;

            sumCall++;
        }
        context.write(key, new Text(sumCall + "_" + sumDuration));
    }

}
```

==将数据上传到Mysql，并通过Redis对数据表进行缓存==

```
/**
 * Mysql的数据格式化输出对象
 */
public class MySQLTextOutputFormat extends OutputFormat<Text, Text> {


    protected static class MySQLRecordWriter extends RecordWriter<Text,Text> {

        private Connection connection =null;
        private Map<String,Integer> userMap=new HashMap<String, Integer>();
        Map<String, Integer> dateMap = new HashMap<String, Integer>();


        public MySQLRecordWriter() {
            // 获取资源
            connection = JDBCUtil.getConnection();
            PreparedStatement pstat = null;
            ResultSet rs = null;

            try {

                String queryUserSql = "select id, tel from ct_user";
                pstat = connection.prepareStatement(queryUserSql);
                rs = pstat.executeQuery();
                while ( rs.next() ) {
                    Integer id = rs.getInt(1);
                    String tel = rs.getString(2);
                    userMap.put(tel, id);
                }

                rs.close();

                String queryDateSql = "select id, year, month, day from ct_date";//将整张表中的数据查出
                pstat = connection.prepareStatement(queryDateSql);
                rs = pstat.executeQuery();
                while ( rs.next() ) {
                    Integer id = rs.getInt(1);
                    String year = rs.getString(2);
                    String month = rs.getString(3);
                    if ( month.length() == 1) {
                        month = "0" + month;
                    }
                    String day = rs.getString(4);
                    if ( day.length() == 1 ) {
                        day = "0" + day;
                    }
                    dateMap.put(year + month + day, id);
                }
            } catch (Exception e) {
                e.printStackTrace();
            } finally {
                if ( rs != null ) {
                    try {
                        rs.close();
                    } catch (SQLException e) {
                        e.printStackTrace();
                    }
                }
                if ( pstat != null ) {
                    try {
                        pstat.close();
                    } catch (SQLException e) {
                        e.printStackTrace();
                    }
                }
            }
        }

        /**
         * 输出数据
         * @param key
         * @param value
         * @throws IOException
         * @throws InterruptedException
         */
        @Override
        public void write(Text key, Text value) throws IOException, InterruptedException {

            String[] values = value.toString().split("_");
            String sumCall = values[0];
            String sumDuration = values[1];

            PreparedStatement pstat = null;
            try {
                String insertSQL = "insert into ct_call ( telid, dateid, sumcall, sumduration ) values ( ?, ?, ?, ? )";
                pstat = connection.prepareStatement(insertSQL);

                String k = key.toString();
                String[] ks = k.split("_");

                String tel = ks[0];
                String date = ks[1];

                pstat.setInt(1, userMap.get(tel));
                pstat.setInt(2, dateMap.get(date));
                pstat.setInt(3, Integer.parseInt(sumCall) );
                pstat.setInt(4, Integer.parseInt(sumDuration));
                pstat.executeUpdate();
            } catch (SQLException e) {
                e.printStackTrace();
            } finally {
                if ( pstat != null ) {
                    try {
                        pstat.close();
                    } catch (SQLException e) {
                        e.printStackTrace();
                    }
                }
            }
        }


        /**
         * 释放资源
         * @param context
         * @throws IOException
         * @throws InterruptedException
         */
        @Override
        public void close(TaskAttemptContext context) throws IOException, InterruptedException {
            if ( connection != null ) {
                try {
                    connection.close();
                } catch (SQLException e) {
                    e.printStackTrace();
                }
            }
        }
    }

    @Override
    public RecordWriter<Text, Text> getRecordWriter(TaskAttemptContext context) throws IOException, InterruptedException {
        return new MySQLRecordWriter();
    }

    @Override
    public void checkOutputSpecs(JobContext context) throws IOException, InterruptedException {

    }


    private FileOutputCommitter committer = null;
    public static Path getOutputPath(JobContext job) {
        String name = job.getConfiguration().get(FileOutputFormat.OUTDIR);
        return name == null ? null: new Path(name);
    }
    public OutputCommitter getOutputCommitter(TaskAttemptContext context) throws IOException, InterruptedException {
        if (committer == null) {
            Path output = getOutputPath(context);
            committer = new FileOutputCommitter(output, context);
        }
        return committer;
    }
}

```

## 1.4 模块④—数据展示

![1660893943056](https://pic-1313413291.cos.ap-nanjing.myqcloud.com/1660893943056.png)

==通过controlller层获取浏览器请求==

```
/**
 * 通话日志控制器对象
 */
@Controller
public class CalllogController {
    @Autowired
    private CalllogService calllogService;

    @RequestMapping("/query")
    public String query() {
        return "query";
    }

    // Object ==> json ==> String
    //@ResponseBody
    @RequestMapping("/view")
    public String view( String tel, String calltime, Model model ) {

        // 查询统计结果 ： Mysql
        List<Calllog> logs = calllogService.queryMonthDatas(tel, calltime);
        System.out.println(logs.size());
        model.addAttribute("calllogs", logs);
        return "view";
    }
}

```

==通过service层调用dao层接口获取数据，并将数据封装为对象==

```
/*
 * 通话日志服务对象
 */
@Service
public class CalllogServiceImpl implements CalllogService {

    @Autowired
    private CalllogDao calllogDao;

    /**
     * 查询用户指定时间的通话统计信息
     * @param tel
     * @param calltime
     * @return
     */
    @Override
    public List<Calllog> queryMonthDatas(String tel, String calltime) {

        Map<String, Object> paramMap = new HashMap<String, Object>();
        paramMap.put("tel", tel);

        if ( calltime.length() > 4 ) {
            calltime = calltime.substring(0, 4);
        }
        paramMap.put("year", calltime);
        System.out.println(paramMap);
        return calllogDao.queryMonthDatas(paramMap);
    }
}
```

==Dao层获取数据==

```
/*
* 通话日志数据访问对象
 */
public interface CalllogDao {
    List<Calllog> queryMonthDatas(Map<String, Object> paramMap);
}
```

==通过Mybatiis配置文件执行SQL对数据库中的数据进行查询==

```
<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE mapper PUBLIC "-//mybatis.org//DTD Mapper 3.0//EN" "http://mybatis.org/dtd/mybatis-3-mapper.dtd">
<mapper namespace="com.atguigu.ct.web.dao.CalllogDao" >


    <select id="queryMonthDatas" resultType="com.atguigu.ct.web.bean.Calllog">
        select * from ct_call where telid = (
            SELECT
                ID
            from ct_user
            where tel = #{tel}
        ) and dateid in (
            SELECT
                ID
            from ct_date
            where year = #{year} and month != '' and day = ''
        )
    </select>

</mapper>
```

# 2.0 项目总结

## 2.1项目背景

​		**通信运营商每时每刻会产生大量的通信数据，例如通话记录，短信记录，彩信记录，第三方服务资费等等繁多信息。数据量如此巨大，除了要满足用户的实时查询和展示之外，还需要定时定期的对已有数据进行离线的分析处理。例如，当日话单，月度话单，季度话单，年度话单，通话详情，通话记录等等。我们以此为背景，寻找一个切入点，学习其中的方法论。当前我们的需求是：统计每天、每月以及每年的每个人的通话次数及时长。**

## **2.2项目流程**

![1660645749939](https://pic-1313413291.cos.ap-nanjing.myqcloud.com/1660645749939.png)

## 2.3项目环境

**1.工具**

| 工具     | 版本   |
| -------- | ------ |
| IDEA     | 2020.2 |
| Maven    | 3.3.9  |
| JDK      | 1.8+   |
| Navicat  | 15     |
| Tomcat   | 8.5.75 |
| CenertOS | 7.0    |
| Xshell   | 7      |

**2.框架信息**

| 框架      | 版本        |
| --------- | ----------- |
| Hadoop    | 2.7.2       |
| Zookeeper | 3.5.7       |
| Hbase     | 1.3.1       |
| Flume     | 1.9.0       |
| Kafka     | 2.1.2-3.0.0 |
| Redis     | 3.0.0       |

**3.集群环境**

|      | hadoop102 | hadoop103 | hadoop104 |
| ---- | --------- | --------- | --------- |
| 内存 | 4G        | 4G        | 4G        |
| CPU  | 2核       | 2核       | 2核       |
| 硬盘 | 50G       | 50G       | 50G       |

|       进程       |    hadoop102     |    hadoop103    |     hadoop104     |
| :--------------: | :--------------: | :-------------: | :---------------: |
|   Hadoop  HDFS   |     NameNode     |                 | SecondaryNameNode |
|                  |     DataNode     |    DataNode     |     DataNode      |
|   Hadoop  YARN   |                  | ResourceManager |                   |
|                  |   NodeManager    |   NodeManager   |    NodeManager    |
| Hadoop历史服务器 | JobHistoryServer |                 |                   |
|    Zookeeper     |  QuorumPeerMain  | QuorumPeerMain  |  QuorumPeerMain   |
|      Kafka       |      Kafka       |      Kafka      |       Kafka       |
|      HBase       |     HMaster      |                 |                   |
|                  |  HRegionServer   |  HRegionServer  |   HRegionServer   |
|                  |       jsp        |       jsp       |        jsp        |

## 2.4项目运行图

**1.查询界面**

![1660645119842](https://pic-1313413291.cos.ap-nanjing.myqcloud.com/1660645119842.png)

**2.统计界面**

![1660645167017](https://pic-1313413291.cos.ap-nanjing.myqcloud.com/1660645167017.png)

![1660645179340](https://pic-1313413291.cos.ap-nanjing.myqcloud.com/1660645179340.png)

![](https://pic-1313413291.cos.ap-nanjing.myqcloud.com/1660645196003.png)

